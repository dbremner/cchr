\chapter{Ontwerp en implementatie} \label{chap:impl}

In dit hoofdstuk gaan we in de op hoe ons CCHR systeem ontworpen en ge\"implementeerd is.

\section{Algemeen} \label{sec:impl-gen}

Zoals reeds aangehaald bestaat de implementatie van een CHR systeem normaal uit twee delen: de {\em compiler} en de {\em runtime}. De compiler zorgt voor een vertaling van de CHR-syntax naar code die uitvoerbaar is op het host-platform, en de runtime bevat alles wat noodzakelijk is om de vertaalde code te kunnen uitvoeren (algemene routines, onderhouden van de constraint store, \ldots).

Onze compiler is zelf in C geschreven en vertaalt CCHR code in enkele stappen tot normale C code, die dan verder door een standaard C compiler vertaald kan worden tot uitvoerbare code (machinetaal voor een specifiek platform). In tegenstelling tot Prolog en Java wordt het programma bij compilatie volledig tot machinetaal herleid, en is er dus geen {\em interpretatie} of {Just-in-time compilatie} meer nodig bij de uitvoering.

\section{De Compiler} \label{sec:impl-comp}

De compiler is het belangrijkste deel van het CCHR systeem. Het algemene concept is sterk gebaseerd op JCHR: we vertalen CHR broncode naar de host-language zelf, die dan door de bestaande compilers voor die taal verder gecompileerd kan worden tot een echt
uitvoerbaar programma. De compiler zelf begint met een parser en lexer om de taalstructuur van de CHR broncode te achterhalen, gevolgd door een omzetting naar een tussenvorm waarop enkele analyses gebeuren, en eindigt met een {\em template}-gebaseerde vertaling naar de uiteindelijke hosttaal. De precieze implementatie verschilt wel danig: \begin{itemize}
  \item De CCHR compiler vertaalt logischerwijs naar C en niet naar Java
  \item De CCHR compiler is zelf ook in C geschreven (de JCHR compiler was zelf ook in Java gemaakt)
  \item De gebruikte lexer en parser zijn gegenereerd met {\em Flex} en {\em Bison}, in plaats van {\em ANTLR}.
  \item In plaats van een extern pakket voor de templates te gebruiken, gebruiken we standaard C macro's.
 \end{itemize}
 
De grote fases zijn min of meer gescheiden van elkaar in de code. Ze zijn elk gedefinieerd in 1 of meerdere aparte bronbestanden, en de datastructuren die gebruikt worden voor de communicatie tussen de verschillende modules zijn op zich weer apart gedefinieerd. Zo zal de parser een {\em Abstract Syntax Tree} als resultaat geven, die enkel door de vertaal/analyse-module gebruikt wordt voor een omzetting naar een tussenvorm, waarop enkele statische analyses uitgevoerd kunnen worden, en die dan eenvoudig te gebruiken is door de codegeneratie om tot C macro's te vertalen.

\subsection{Algemeen}

De algemene werking van de CCHR compiler is als volgt: \begin{itemize}
  \item Alle op de commandolijn opgegeven bestanden worden doorlopen, en letterlijk gekopi\"eerd naar de uitvoer (C).
  \item Als in een van de bestanden een {\em cchr-blok} gevonden wordt: \begin{itemize}
    \item De {\em parser} wordt aangeroepen met dat cchr-blok als invoer.
    \item De {\em parser} roept zelf de {\em lexer} aan om syntactische elementen te herkennen.
    \item De {\em parser} bouwt een {\em abstract syntax tree} (AST).
    \item De AST wordt geanalyseerd, en een tussenvorm wordt opgebouwd.
    \item Op de tussenvorm worden optimalisaties doorgevoerd.
    \item Uiteindelijk wordt de tussenvorm opgezet naar een sequentie van C macro's.
    \item Deze C macro's worden in het uitvoerbestand (C) op de plaats gezet waar het {\em cchr-blok} stond.
  \end{itemize}
\end{itemize}

\subsection{De lexer}

De lexer is geschreven met behulp van Flex. Op de website van Flex vinden we: \begin{quote}
  Flex is a fast lexical analyser generator. It is a tool for generating programs that perform pattern-matching on text.
\end{quote}

Op basis van een bestand met definities van patronen, in de vorm van {\em regular expressions}, kan Flex een C bronbestand genereren dat heel snel een stuk input kan splitsen in de opgegeven patronen. 

Deze op deze wijze bekomen {\em lexer} vormt de eerste fase van het compilatie-proces. Ze herkent de opeenvolgende sleutelwoorden, operatoren, symbolen (kortweg {\em tokens}) van de brontaal, en geeft ze door aan de {\em parser}.

\subsection{De parser}

De parser is geschreven met behulp van Bison. Op de website van Bison vinden we: \begin{quote}
  Bison is a general-purpose parser generator that converts an annotated context-free grammar into an LALR(1) or GLR parser for that grammar.
\end{quote}

Er kan opgemerkt worden dat de werkwijze van Bison sterk lijkt op de CCHR compiler zelf. Er wordt ook uitgegaan van een andere taal die in C ingebed kan worden, en met behulp van een template-gebaseerde methode wordt pure C code gegenereerd.

Hiervoor is de grammaticale structuur van CCHR beschreven als een Bison {\em Context-Free Grammar}, met semantische acties erbij die een AST genereren. Er moet wel opgemerkt worden dat hoewel CCHR toelaat arbitraire C code op te nemen, de CCHR grammatica geen volledige C grammatica bevat. Ingebedde C code wordt namelijk niet volledig geparset, slechts tot op de hoogte dat noodzakelijk is
om het begin en het einde ervan te herkennen. Dat wil bijvoorbeeld zeggen dat \code{1+2*(3-4)} gewoonweg als \code{1 + 2 * ( 3 - 4 )} beschouwd wordt, en niet als \code{+(1,*(2,-(3,4)))}. Het letterlijk doorgeven van C expressies volstaat, aangezien alles toch nog
door de C compiler zelf moet.

Voor de {\em tokens} die de grammatica als basisblokken gebruikt, wordt beroep gedaan op de {\em lexer}.

Het resultaat hiervan is dus een AST, die echter helemaal niet geschikt is om converties en analyses op uit te voeren. Alle variabelen, constraints, \ldots zijn nog steeds beschreven als een hoop tekenreeksen. In de volgende stap wordt dit omgezet naar een werkbaar formaat. 

\subsection{De tussenvorm}

Na deze stap wordt de AST omgezet naar een nieuwe datastructuur, waarbij constraints, variabelen, regels, \ldots als aparte datastructuren in plaats van als tekenreeksen beschreven worden. Dit kan echter niet echt object-geori\"enteerd gebeuren, aangezien C dat niet ondersteunt.

De reden om de parser niet onmiddellijk via semantische acties deze tussenvorm te laten genereren is meer vrijheid in de taal te kunnen toelaten. Zo is het nu bijvoorbeeld mogelijk om een constraint pas te defini\"eren nadat die in een CHR regel gebruikt is.

Tijdens de omzetting van AST naar deze tussenvorm worden volgende transformaties doorgevoerd: \begin{itemize}
\item Alle verwijzingen naar constraints, variabelen, opties, \ldots worden herkend.
\item Alle regels worden omgezet naar HNF (Head Normal Form), waarbij alle expressies als parameters van contraints in de head die geen unieke variabelen zijn door een nieuwe variabele + een extra guard vervangen worden.
\item Macros worden vervangen door hun definitie.
\item Constraint occurrences worden bepaald (in welke rules en op welke plaats daarin elke constraint voorkomt).
\item Variabele occurrences worden bepaald (in welke constraint occurrence en op welke plaats daarin elke variabele voorkomt).
\item Afhankelijkheden tussen variabelen en statements worden bepaald.
\item Met deze afhankelijkheden wordt voor elke constraint occurrence een goede ``join ordering'' bepaald (zie sectie~\ref{ssec:joinorder}).
\end{itemize}

\subsection{Code generatie}

In de laatste fase van het vertalingsproces wordt de tussenvorm omgezet naar C code. Bij JCHR wordt van de template engine FreeMarker gebruik gemaakt. Het voordeel van templates gebruiken is duidelijk: de code die door de compiler zelf gegenereerd moet worden is algemener en beschrijft het proces op hoger niveau. Implementatie details zoals datastructuren kunnen dan onafhankelijk van de compiler uitgewerkt worden, wat het geheel flexibeler maakt en de kans op fouter beperkt.

In C bestaat echter reeds een gestandaardiseerd macro-systeem. We hebben er dan ook voor gekozen om deze C macros te gebruiken in plaats van een apart template engine. Het programma dat de macro-vertalingen doet, de C preprocessor, is standaard deel van het compilatieschema van C, waardoor het overbodig is om in de CCHR compiler deze vertaling te doen.

Het resultaat is dat het volledige template-vertaalproces verschoven wordt van de CCHR compiler naar het C compilatie-schema, en de uitvoer van de CCHR compiler is een sequentie van C macros in plaats van echte C code.

Het voordeel hiervan is dat de uitvoer van de CCHR compiler heel leesbaar blijft, en onafhankelijk blijft van enkele details. Zo is het mogelijk om een debug-versie van het CCHR programmatie te cre\"eren zonder de CCHR compiler opnieuw te moeten uitvoeren, enkel het resultaat ervan hercompileren met de C compiler en een andere optie volstaat. Het belangrijkste nadeel is de moeilijkheden dat het veroorzaakt bij het debuggen. 

\subsection{Uitvoer module}

Uiteindelijk roept de codegenerator een uitvoer module aan, die verantwoordelijk is voor de code mooi ge\"indenteerd weg te schrijven naar het uitvoerbestand, en ondertussen informatie bij te houden over het aantal geschreven regels. Dit is nodig omdat er lijnen van de vorm: \begin{Verbatim}
  #line "source.cchr" 16
  ...
  #line "source.c" 214
\end{Verbatim}
in de uitvoer gezet worden, die de C compiler hints geven over waar de code in het bestand vandaan kwam, om zinvollere waarschuwingen te kunnen geven. 

\section{Gegenereerde code} \label{sec:impl-code}

Zoals gezegd bestaat de gegenereerde code uit C macros. In dit stuk gaan we in op de structuur van die gegenereerde code.
Eerst geven we een inleiding op de C voorvertaler, en dan werken we een voorbeeld stap voor stap uit, om te eindigen bij de effectieve gegenereerde code die in de appendix te vinden is.

\subsection{C voorvertaler}

Eerst een korte inleiding over de C voorvertaler (``{\em preprocessor}'').

Het is een component die deel is van het standaard C compilatieproces (preprocessor, compiler, assembler, linker), die vooral gebruikt om platform-afhankelijke definites in te voegen in C programma. Zo bijvoorbeeld kan met het preprocessor {\em directive} \begin{Verbatim}
  #include <stdio.h>
\end{Verbatim}
Het {\em headerbestand} \code{stdio.h} ingeladen worden. Volgens de standaard zal dit bestand definities opnemen voor een aantal datatypes en functies nodig voor invoer/uitvoerroutines. 

Alle ``instructies'' die deze preprocessor kent heten {\em directives} (directieven), en moeten op een aparte lijn in het bronbestand staan, te beginnen met een hekje (\code{\#}). De belangrijkste directives die wij gebruiken zijn \code{\#include}, en \code{\#define}. Dat laatste dient om een macro te defini\"eren.

Macros zijn {\em tokens} die gedefinieerd worden als te substitueren door een reeks andere tokens. De eenvoudigste vorm, ook objectvorm genaamd, is: \begin{Verbatim}
  #define FOO bar(1);
\end{Verbatim}
wat aangeeft dat vanaf hier in de code ``\code{FOO}'' vervangen zal worden door ``\code{bar(1);}''. Macros kunnen echter ook parameters aannemen, de functionele vorm: \begin{Verbatim}
  #define FOO(par) bar(par1,par1+1);
\end{Verbatim}
waarbij bij voorbeeld de code ``\code{FOO(7)}'' vervangen zal worden door ``\code{bar(7,7+1);}''. Zulke macros hebben ook ondersteuning voor {\em variable arguments}: \begin{Verbatim}
  #define FOO(par,...) bar(par,__VA_ARGS__)
\end{Verbatim}
Hier zal ``\code{\_\_VA\_ARGS\_\_}'' de plaats innemen van alle argumenten die na par komen bij de vermelding van \code{FOO}. Zo zal bijvoorbeeld ``\code{FOO(sys,1,2)}'' vervangen worden door ``\code{bar(sys,1,2)}''.
De laatste mogelijkheid die we gebruiken is {\em token pasting}: \begin{Verbatim}
  #define FOO_1(arg) run(arg)
  #define FOO_2(arg) test(arg)
  #define BAR(par,sys) FOO_##par(sys)
\end{Verbatim}
De \code{\#\#} zorgt hier dat 2 tokens aan elkaar geplakt worden, en onderwerpt het resultaat terug aan macro-expansie. Zo zal in bovenstaand voorbeeld ``\code{BAR(1,2)}'' vervangen worden door ``\code{run(2)}'', maar ``\code{BAR(2,1)}'' door ``\code{test(1)}''.

In de komende tekst zal vaak verwezen worden naar macros, sommigen daarvan staan in het macro-definitie bestand, anderen worden door de compiler gegenereerd. Gegenereerde macros zullen we daarom ook steeds ``gegenereerde macros'' noemen, om verwarring te vermijden.

\subsection{Algemeen} \label{ssec:impl-code-alg}

Met het oog de gegenereerde macro-code niet te overladen met informatie die over heel het programma hetzelfde is, zoals de lijst van alle chr-constraints, is gekozen zoveel mogelijk op een algemene manier op te slagen. Dit vraagt een woordje uitleg.

Stel dat we dit CCHR blok zouden willen vertalen: \begin{Verbatim}
cchr {
  constraint fib(int,long long),init(int);

  begin @ init(_) ==> fib(0,1LL), fib(1,1LL);
  calc @  init(Max), fib(N2,M2) \ fib(N1,M1) <=>
    alt(N2==N1+1,N2-1==N1), N2<Max |
    fib(N2+1, M1+M2);
}
\end{Verbatim}
De volledige compiler uitvoer kan u vinden in sectie~\ref{sec:out-fib}.

De eerste belangrijke lijn die gegenereerd wordt is deze: 
\begin{Verbatim}
  #define CONSLIST(CB) CB##_D(fib_2) CB##_S CB##_D(init_1)
\end{Verbatim}
Deze lijn defini\"eert welke chr constraints allemaal bestaan. Ze is heel flexibel in gebruik, de aanroeper moet zelf 2 macros of functies voorzien: een voor het defini\"eren van een constraint, en een voor wat er tussen 2 constraints moet gebeuren. Zo is het mogelijk om code te laten genereren voor elke constraint, gescheiden met comma's, mits: \begin{Verbatim}
  #define CB_D(con) CODE_VOOR_CONSTRAINT(con)
  #define CB_S ,
  CONSLIST(CB)
\end{Verbatim}

Deze techniek wordt echter voor een stuk meer gebruikt dan enkel het aanduiden van de bestaande chr constraints. Er worden zulke index-macros gedefinieerd voor: \begin{itemize}
\item Welke chr constraints bestaan.
\item De occurrences van elke constraint.
\item Aantal kept/removed constraints in elke rule
\item Wat in propagation history bij te houden
\item Welke indexen nodig zijn, en waarover
\end{itemize}
Verder worden er nog gelijkaardige, maar eenvoudigere constructies gegenereerd voor constructor-, destructor-, add en kill routines per chr constraint.

Dan volgen nog enkele macros die de het mechanisme op hoog niveau beschrijven wat er voor elke constraint occurrence moet gebeuren. Hier gaan we zodadelijk op in.

Als afsluiter van de gegenereerde code staat een ``\code{CSM\_START}'', deze macro is gedefinieerd in het algemene macro-definitie bestand (zie runtime), en zal gebruikmakende van alle eerder gegenereerde macrodefinities expanderen tot de uiteindelijke C code. Daaruit volgt dat alle echte CCHR-code schijnbaar op de lijn van deze \code{CSM\_START} komt te staan.

\subsection{Constraint occurrences}

Voor elke constraint occurrence wordt een stuk code gegenereerd in de vorm van een aparte macro definitie. We zullen hier de basisopbouw geven, en later optimalisaties doorvoeren.

De naam die aan de gegenereerde macro voor een constraint occurrence moet van de vorm ``\code{CODE\_\argu{occurrence-naam}}'' zijn, en geen parameters hebben. De benaming voor de occurrence moet gewoon overal dezelfde zijn in de gegenereerde code. In praktijk gebruikt de compiler benamingen als ``\code{\argu{constraint}\_\argu{ariteit}\_\argu{rule}\_\argu{positie}}''. Positie is hierbij de letter \code{K} voor kept constraints, of de letter \code{R} voor removed constraints, gevolgd door een getal dat aanduidt de hoeveelste occurrence van dat type (removed of kept) het is binnen de gegeven rule, te beginnen bij 1.

Dan komen we bij de inhoud van deze macros. Het is hier dat het voordeel van een template-gebaseerde code generatie tot uiting komt: het algorithme wordt niet als C code gegenereerd, maar als een sequentie van macros. Deze set van macros is CSM gedoopt (Constraint Solver Macros), en een volledige lijst kan u vinden in appendix~\ref{chap:csm}. Het kan nuttig zijn de lijst erbij te nemen bij de komende uitleg, aangezien de precieze betekenis van de CSM macros hier niet meer uitgelegd wordt.

Als eerste versie vertrekken we van een imperatieve versie van de basisuitvoering beschreven in \cite{tomsphdthesis}:
\begin{itemize}
  \item Eerst ervoor zorgen dat de actieve constraint bestaat (\code{CSM\_MAKE}), en toegevoegd is aan de constraint store (\code{CSM\_NEEDSELF}).
  \item We itereren over alle partner constraints (de constraint occurrences in de huidige rule behalve de actieve), mbv. \code{CSM\_LOOP}.
  \item We controleren of er geen dubbels zijn in de verschillende partner constraints (mbv.  \code{CSM\_DIFF} en \code{CSM\_DIFFSELF} binnen een \code{CSM\_IF}).
  \item We controleren of de gevonden combinatie nog niet reeds geprobeerd is (mbv. \code{CSM\_CHECKHIST}).
  \item We defini\"eren alle lokale variabelen (met \code{CSM\_DECLOCAL} en \code{CSM\_DEFLOCAL}).
  \item We controleren of aan alle guards voldaan is (mbv. \code{CSM\_IF} en de constraint argumenten met \code{CSM\_ARG} en \code{CSM\_LARG} geschreven).
  \item We voegen de gevonden combinatie toe aan de propagation history (mbv. \code{CSM\_HISTADD}).
  \item We verwijderen eventuele removed constraints uit de constraint store (mbv. \code{CSM\_KILL} en \code{CSM\_KILLSELF}).
  \item We voeren de body van de chr rule uit, met de verwijzingen naar lokale variabelen vervangen door \code{CSM\_LOCAL}-macros en de constraint argument door \code{CSM\_ARG} en \code{CSM\_LARG}.
  \item Als de actieve constraint uit de constraint store verwijderd is, stop dan met de afhandeling (\code {CSM\_DEADSELF} en \code{CSM\_END}).
\end{itemize}

Met deze versie zijn enkele problemen, die misschien niet op het eerste zicht duidelijk zijn: \begin{itemize}
  \item Zodra een \code{CSM\_KILL} gebeurd is, kan \code{CSM\_LARG} niet meer gebruikt worden, omdat naar een onbestaande constraint verwezen kan worden (of erger nog: naar een andere constraint suspension die nu op die plaats staat). Daarom zullen we de constraint argumenten voor de uitvoering van de body opslagen in lokale (onwijzigbare) variabelen, mbv. \code{CSM\_IMMLOCAL}. Als er dan verder naar verwezen wordt in de body, gebruiken we gewoon \code{CSM\_LOCAL} ipv. \code{CSM\_LARG}.
  \item Het is mogelijk dat een constraint-argument verwijst naar een apart gealloceerd object, dat dmv. een destructor aangegeven is voor vernietiging bij verwijderen van de constraint suspension. Deze destructor kan echter niet aangeroepen worden door \code{CSM\_KILL}, omdat code verder in de body misschien nog naar het apart gealloceerd object kan verwijzen. Daarom voeren we een \code{CSM\_DESTRUCT} in voor elke \code{CSM\_KILL} of \code{CSM\_KILLSELF}, die pas na de body aangeroepen wordt.
  \item Wanneer de actieve constraint nog niet uit de constraint store verwijderd is, maar een van de voorgaande partner constraints al wel, dan moet onmiddellijk het volgende element van die iterator voor die partner constraint gekozen worden, om te vermijden dat de body toegepast zou worden voor een op dat moment niet meer bestaande constraint suspension. Daarom voeren we na de controle of de actieve constraint nog in de store zit, ook controles in voor alle \code{CSM\_LOOP}s, van buiten naar binnen, dmv. \code{CSM\_DEAD}, met een \code{CSM\_LOOPNEXT} op de betrokken variabele in. Deze controle is echter niet nodig voor de binnenste lus, aangezien daar sowieso onmiddellijk het volgende element gekozen zal worden.
\end{itemize}

\subsection{Optimalisaties}

Deze eerste versie van het compilatieschema is echter voor verbetering vatbaar. Voor een gedetailleerde uitleg over de optimalisaties en waarom ze toegestaan zijn, verwijzen we opnieuw naar \cite{tomsphdthesis}. 

{\bf Dubbels per type}: Het is enkel nodig om te controleren op dubbele constraint suspensions (\code{CSM\_DIFF} en \code{CSM\_DIFFSELF}) tussen suspensions van hetzelfde constraint type.

{\bf Propagation history}: Men hoeft enkel een propagation history bij te houden voor rules die geen removed constraints hebben. Deze laatste kunnen immers sowieso geen 2x uitgevoerd worden.

{\bf Destruction}: Indien een destructor aangeroepen moet worden voor een bepaalde constraint suspension, is het niet nodig hiermee te wachten tot na de uitvoering van de gehele body. Dit kan (meestal) gedaan worden zodra niet meer naar een variabele van die constraint verwezen wordt in de rule. De CCHR compiler zal de \code{CSM\_DESTRUCT} macro dan ook plaatsen na het laatste stuk body dat naar een variabele ervan verwijst.

{\bf Late Storage}: Het is wenselijk om het aanmaken van een constraint suspension, en zeker het eigenlijke toevoegen ervan aan de constraint store, zoveel mogelijk uit te stellen. Dit eerste bespaart geheugen, en dit tweede kan de snelheid ten goede komen, aangezien er ondertussen minder elementen in de store zijn om over te itereren. We zorgen ervoor dat de suspension aangemaakt is juist voor het zoeken naar partner constraints van een propagate-overgang\footnote{Een propagate-overgang komt in onze uitvoer overeen met een occurrence-macro waarbij de actieve constraint geen removed constraint is}, door de \code{CSM\_MAKE} enkel te plaatsen aan het begin van ``kept'' occurrence macros. Verder zorgen we er pas voor dat de constraint suspension in de store zit aan het begin van de uitvoering van de body van zo'n propagate-overgang. De \code{CSM\_NEEDSELF} wordt dus geplaatst voor de body van zo'n occurrence.

{\bf Simplification}: Bij simplificatie-overgangen is er zekerheid dat na uitvoering van de body, de actieve constraint zich niet meer in de store zal bevinden. We hebben dus geen \code{CSM\_DEADSELF} meer nodig om te controleren of een \code{CSM\_END} mag. Dit kan uitgebreid worden tot propagation-overgangen die partner constraints verwijderen. Hierbij kan de \code{CSM\_DEAD} conditie rond de \code{CSM\_LOOPNEXT} weggelaten worden. Daarbij komt nog dat na zo'n niet-conditionele \code{CSM\_END} of \code{CSM\_LOOPNEXT} geen verdere checks voor de diepere lussen meer nodig zijn, en dus volledig weggelaten kunnen worden. Het gebruik van deze expliciete \code{CSM\_LOOPNEXT} macros komt overeen met wat in JCHR ``backjumping'' genoemd wordt.

{\bf Generation}: Er kan aangetoond worden, dat indien tijdens de uitvoering van de body met een bepaalde actieve constraint suspension, diezelfde constraint suspension gereactiveerd werd, er geen nood meer is om nog verder te proberen rules erop toe te passen. Alle mogelijke rules zijn immers al toegepast tijdens de reactivatie. Dit wordt geimplementeerd door simpelweg in de definitie van \code{CSM\_DEADSELF} op te nemen, dat deze na reactivatie van zichzelf ook true is.

\subsection{Join ordering} \label{ssec:joinorder}

Een meer algemene verbetering die aangebracht kan worden aan voorgaand compilatieschema, is wat men ``join ordering'' noemt, zoals vermeld in \cite{duck:optimizing}. Tot hiertoe hebben we de volgorde waarin ge\"itereerd wordt over de verschillende partner constraints ongedefinieerd gelaten, maar een juiste keuze kan veel versnelling bij de uitvoering mogelijk maken.

In het algemeen komt het neer op zoveel mogelijk statements en voorwaardes die gecontroleerd worden voor we bij de uitvoering van de eigenlijke body zo snel mogelijk te doen, dwz. binnen zo weinig mogelijk lussen. Een overzicht: \begin{itemize}
  \item Guards (ook impliciete, door HNF convertie)
  \item Controles op dubbele constraints
  \item Propagation-history controles
  \item Definities van lokale variabelen
  \item Lokale statements in de guard, waar we tot hiertoe over zwegen.
\end{itemize}
In bovenstaand compilatieschema gebeuren al deze dingen pas zodra over alle partner constraints gelopen is, terwijl heel wat mogelijkheden al op voorhand uitgesloten zouden kunnen worden. Daarom gaan we proberen zoveel mogelijk van deze dingen reeds tussen de lussen door te controleren. Ze kunnen echter afhankelijk zijn van constraints, of van contraint-argumenten en lokale variabelen, die zelf ook van eerder gedefinieerde dingen afhankelijk kunnen zijn.

Hiervoor gebruiken we volgend algoritme in de compiler: \begin{itemize}
  \item We itereren over alle mogelijke volgordes van iteratie ($O(N!)$ combinaties, met $N$ het aantal partner constraints).
  \item Voor elke volgorde proberen we elke controle of statement zo vroeg mogelijk te plaatsen.
  \item We berekenen een ``score'', die aangeeft hoe snel deze volgorde verwacht wordt te zijn. Deze wordt bepaald door aan alle acties een gewicht toe te kennen, en deze te vermenigvuldigen met een factor voor elke lus waarbinnen ze staat.
  \item Uiteindelijk de volgorde met de laagste score te kiezen.
\end{itemize}
De gewichten die gebruikt worden zijn redelijk eenvoudig, en komen vermoedelijk niet overeen met de de realiteit. De bekomen volgorde zal daardoor vaak niet optimaal zijn, maar het verschil kan al wel aanzienlijk zijn.

\subsection{Indexen}

Na al deze verbeteringen blijft het meeste tijd verloren gaan in het opzoeken van de partner constraints. In sommige gevallen kunnen we echter al weten welke partner constraints nodig zijn, door indexen aan te leggen en te onderhouden die aangeven welke constraint suspensions allemaal een of meerdere waardes als bepaalde argumenten hebben. Hoe dit ge\"implementeerd is wordt uitgelegd in sectie~\ref{sec:impl-runtime}.

Om deze indexen te gebruiken in CSM, is het nodig ze eerst in een index-macro te defini\"eren zoals aangehaald in sectie~\ref{ssec:impl-code-alg}. Daarna is het ook nodig om in plaats van de traditionele \code{CSM\_LOOP} macro enkele andere macros te gebruiken. Eerst en vooral moet gedeclareerd worden dat een bepaalde variabele als index-iterator gebruikt gaat worden (met \code{CSM\_DEFIDXVAR}). Daarna moeten de op te zoeken waardes voor de verschillende argumenten ingevuld worden met \code{CSM\_SETIDXVAR}, en uiteindelijk moet ge\"itereerd worden met \code{CSM\_IDXLOOP} of \code{CSM\_IDXUNILOOP}. Over het verschil tussen beide gaan we dadelijk in.

Deze optimalisatie is degene die de belangrijkste snelheidsverbetering teweegbracht bij de implementatie, wat logisch is, bij sommige problemen maakt het de uitvoering een grootte-orde sneller door onmiddellijk de juiste constraint te vinden, in plaats van mogelijks er duizenden te moeten doorlopen.

Dit is ge\"implementeerd door bepaalde guards als speciaal te herkennen en aanleiding te laten geven tot indexen. Op dit moment gebeurt dit enkel voor logische (\code{==}) of binaire gelijkheden (\code{eq(\ldots)}, een eigen aanvulling). Hierbij komt ook het \code{alt} sleutelwoord kijken, dat zorgt voor verschillende mogelijkheden hoe de guard bekeken wordt. Uiteindelijk wordt tijdens de join ordering elke constraint waarvan 1 of meer argumenten door een simpele gelijkheid aan een expressie (van bekende waardes) bepaald kunnen worden, door een index-iterator beschreven en gezorgd, in plaats van door een normale iterator plus guard.

\subsection{Existenti\"ele en universele iteratoren}

Tijdens het uitvoeren van CCHR code wordt er ge\"itereerd over constraints in verschillende geneste lussen, en middenin die lussen worden er constraints verwijderd, toegevoegd, en gereactiveerd. Dit zorgt ervoor dat de toestand van de constraint store, en indien er indexen gebruikt worden, ook deze indexen tijdens het itereren op allerlei mogelijke manieren kunnen veranderen.

Iteratoren die bestand zijn tegen willekeurige wijzigingen en garanderen dat elk element dat uiteindelijk in de store zit ook effectief doorlopen is, zijn heel moeilijk effici\"ent te schrijven. We eisen dan ook niet dat \code{CSM\_LOOP} en consoorten eze functionaliteit aanbieden. Het is echter wel zo, dat constraint suspensions die tijdens het itereren toegevoegd worden aan de store, niet hoeven te worden gecontroleerd als mogelijke partner constraints, en dus niet noodzakelijk moeten overlopen worden door de iteratoren. Ze zijn immers reeds geactiveerd toen ze zelf toegevoegd werden, en ze zouden dus ondertussen reeds alle mogelijke transities met de huidige actieve constraint als partner constraint reeds moeten hebben doorgaan. Dit vergemakkelijkt de zaak duidelijk.

We zitten echter nog steeds met het probleem dat onze iteratoren wijzigingen in de constraint store moeten aankunnen tijdens het itereren. Blijkt echter dat dit niet altijd nodig is. Indien de simplification optimalisatie en expliciete backjumping ge\"implementeerd zijn, blijkt dat wanneer een rule minstens 1 removed constraint bevat (eventueel de actieve constraint), er na het toepassen van de body van een regel sowieso wordt gesprongen naar de volgende waarde voor de ``meest buitengelegen'' iterator voor een removed constraint, of verder. Hieruit volgt dat de lussen die daarbinnen zitten nooit moeten verderlopen eens de body is uitgevoerd.

Om die reden gaan we voor iteratoren waar het ingewikkeld is, 2 verschillende versies aanbieden: \begin{itemize}
\item een versie die slechts volgende mogelijkheden geeft totdat de constraint store gewijzigd kan zijn: de {\em existenti\"ele} iterator.
\item een versie die het algemene geval ook aankan: de {\em universele} iterator
\end{itemize}

Een universele iterator kan een veel grotere kost hebben om uitgevoerd te worden, wat ook in rekening wordt gebracht bij de kost berekening voor de join ordering.

\section{CSM Definities} \label{sec:impl-csm}

Bij SWI-Prolog en JCHR kon een duidelijk onderscheid gemaakt worden tussen gegenereerde code en runtime. Bij CCHR is het echter de vraag of we de definities van de CSM macros tot runtime kunnen rekenen. Het is namelijk geen code die tijdens de uitvoering nodig is, maar code die nodig is om de gegenereerde code naar een uitvoerbaar bestand te kunnen omzetten. Daarom zullen we de de daarin behandelde problemen hier in een aparte sectie bespreken.

De belangrijkste taak van CSM is de gebruikte datastructuren afschermen van de gegenereerde code, zodat deze beide onafhankelijk gewijzigd kunnen worden. We zullen daarom eerst even ingaan op de gebruikte datastructuren, en dan de implementatie ervan zelf bespreken.

\subsection{Noodzakelijke datastructuren} \label{ssec:impl-csm-ds}

{\bf Constraint store} De belangrijkste datastructuur is uiteraard degene voor de constraint store. Het moet een structuur zijn die toelaat heel snel constraints toe te voegen, te verwijderen en erover te itereren. De volgorde waarin is in principe niet zo van belang, maar het niet-teruggeven van elementen die tijdens het itereren zelf zijn toegevoegd is een pluspunt. Dynamische allocaties tijdens de uitvoering blijven liefst zo veel mogelijk beperkt.

{\bf Propagation history} Er moet ook een propagation history bijgehouden worden. Deze moet toelaten snel een bepaalde combinatie van constraint suspensions op te zoeken en verwijderen wanneer een van de betrokken constraint suspensions uit de store verwijderd wordt.

{\bf Indexen} Er is een datastructuur nodig om de indexen in bij te houden. Deze moet voor 1 of meerdere argumenten van een bepaalde constraint voor elke (combinatie van) waardes voor deze argumenten een lijst kunnen bijhouden van constraint suspensions die deze (combinatie van) waardes als argumenten heeft.
 
\subsection{De constraint store} \label{ssec:impl-csm-cs}

Voor de constraint store is gekozen voor een verzameling doubly-linked lists, die een gemeenschappelijk gealloceerd blok delen te gebruiken. Het gealloceerd blok wordt beschouwd als een array van elk elementen, waarbij elk element: \begin{itemize}
  \item Een verwijzing naar het volgende element heeft.
  \item Een verwijzing naar het vorige element heeft.
  \item Een uniek ID heeft (of $0$ voor ongebruikte elementen).
  \item Een datablok heeft.
\end{itemize}
De eerste elementen van de array worden niet echt gebruikt voor data in op te slagen, maar enkel als aanduidingen voor waar de lijsten voor elk type constraint beginnen. Aan elk contraint type wordt immers een getal van 0 tot N-1 toegekend.
De ``lege'' plaatsen in de array worden in een aparte (single) linked list bijgehouden, om snel een nieuwe plaats te kunnen innemen. 

\subsection{De propagation history} \label{ssec:impl-csm-ph}

\subsection{De index} \label{ssec:inpl-csm-index}

\section{Runtime} \label{sec:impl-rt}

Als ``runtime'' beschouwen we alle software-componenten die gemeenschappelijk zijn voor alle CCHR programma's, met uitzondering van de CSM definities die reeds behandeld zijn.

Er zijn slechts enkele stukken die nog overblijven om tot deze laag te beschouwen: \begin{itemize}
  \item De code voor de doubly-linked lists, die voor de constraint store gebruikt werd.
  \item De code voor de op union-find gebaseerde code om met logische variabelen te werken.
  \item De code om de hashtables te onderhouden die voor propagation history en indexen gebruikt werd.
  \item De code voor de hashfunctie voor bovenstaande hashtable.
\end{itemize}

\subsection{Doubly-linked lists} \label{sec:impl-rt-dll}

\subsection{Logische variabelen} \label{sec:impl-rt-log}

\subsection{De hashtable} \label{sec:impl-rt-ht}

\subsection{De hashfunctie} \label{sec:impl-rt-hf}

% Een van de meest algemene afwegingen die gemaakt moeten worden, is hoeveel de compiler doet, en hoeveel aan de runtime overgelaten wordt. In het algemeen stelt vast dat men hoe meer concepten door de compiler vertaald worden (en dus hoe eenvoudiger de runtime wordt), hoe effici\"enter het resultaat kan worden. De compiler is immers in staat
% 
% In het kader van effici\"entie, wat de belangrijkste doelstelling was, is de eigenlijke runtime beperkt. Enkel de code voor het
% bepalen van hashfuncties en de definitie van enkele fundamentele datatypes- en structuren kan echt als runtime beschouwd worden.
% Alle andere dingen worden (indirect) door de compiler gegenereerd. De eigenlijke output van de compiler is nog geen definitieve
% uitvoerbare C code, maar slechts C macro's die 

