\chapter{Voorbeelden en Vergelijkingen} \label{chap:bench}

\section{Benchmarks}

\newcommand{\benchfig}[2]{
\begin{figure}[htbp]
\begin{center}
\includevector{1}{fig/bench-#1}
\caption{\label{fig:bench-#1}#2}
\end{center}
\end{figure}
}

In dit hoofdstuk worden enkele voorbeelden bekeken en gezien hoe goed ze presteren in de verschillende CHR implementaties. Van elk van deze voorbeelden is een ook pure C implementatie geschreven, om een idee te hebben hoe ver (C)CHR er nog van af staat.

\TODO{Benchmarksysteem beschrijven}

\subsection{Grootst gemene deler} \label{sec:bench-gcd}

Het eerste voorbeeld dat beschouwd wordt, is een programma dat de grootst gemene deler van 2 getallen kan bepalen. Het werkt door zolang er 2 getallen groter dan 0 zijn, het kleinste van het grootste af te trekken. 
\begin{exCode}
\begin{Verbatim}[frame=single,numbers=left]
cchr {
  constraint gcd(int);

  triv @ gcd(0) <=> true;
  dec @ gcd(N) \ gcd(M) <=> M>=N | gcd(M-2);
}
\end{Verbatim}
\caption{\label{code:fib} Grootst gemene deler in CCHR}
\end{exCode}
\benchfig{gcd}{Grootst gemene deler benchmark}
De benchmark resultaten vindt u in figuur~\ref{fig:bench-gcd}. Op de grafiek is te zien hoe de CCHR versie slechts een factor 3 ongeveer trager is dan de pure C implementatie. Het verschil met de SWI-Prolog versie is heel groot, meer dan een factor 1000. Dit is vooral te wijten aan de extreem snelle lussen die in C mogelijk zijn in vergelijking met Prolog. De eigenlijke uitvoering van het algoritme komt immers neer op een variabele die van een groot getal aftelt tot 0. Merk op dat hier de ineffici\"ente versie van het algoritme gebruikt wordt, gebruik makende van een aftrekking in plaats van een modulus-bewerking wordt. Dit om de uitvoeringstijd van het algoritme meetbaar te houden. De berekende waardes zijn $gcd(5,1000 X)$, met $X$ de ``problem size''. Deze test was in JCHR niet uit te voeren, wegens vrij snel een stack overflow.

\subsection{Fibonacci getallen} \label{sec:bench-fib}

Als tweede voorbeeld wordt een programma beschouwd dat de getallen van Fibonacci berekent. Deze keer een iets ingewikkelder algoritme: er is in elke taal gebruikt gemaakt van een bibliotheek om met grote getallen (willekeurige lengte) te kunnen werken gebruiken, en alle kleinere getallen bijhouden. Hier is de code:
\begin{exCode}
\begin{Verbatim}[frame=single,numbers=left]
#include <gmp.h>
typedef struct {
  mpz_t v;
} bigint_t;

cchr {
  constraint fib(int,bigint_t) option(destr,{mpz_clear($2.v);});
  constraint init(int);
  
  begin @ init(_) ==> 
    bigint_t Z=, bigint_t Y=, 
    { mpz_init_set_si(Z.v,1); mpz_init_set_si(Y.v,1); },
    fib(0,Z), fib(1,Y);

  calc @ init(Max), fib(N1,M1), fib(N,M2) ==>
  alt(N1+1==N,N1==N-1), N<Max |
    bigint_t sum=,
    { mpz_init(sum.v); mpz_add(sum.v,M1.v,M2.v); },
    fib(N+1, sum);
}
\end{Verbatim}
\caption{\label{code:fibgmp} Fibonacci met GMP in CCHR}
\end{exCode}
\benchfig{fib}{Fibonacci benchmark}

Er wordt gebruik gemaakt van de {\em GNU Multiprecision Library}, die de mogelijkheid biedt om met willekeurig grote getallen te werken. De C versie van het programma gebruikt ook GMP, en SWI-Prolog gebruikt het intern ook. In JCHR maken wordt de java.math.BigInteger klasse gebruikt. De resultaten kan u zien in figuur~\ref{fig:bench-fib}. De CCHR versie lijkt korter en korter bij de uitvoeringstijd van de C versie te komen. Dit kan te verklaren zijn door dat een groot deel van het rekenwerk door GMP gebeurt, en naarmate de getallen groter worden, meer en meer. Er blijft wel een duidelijk snelheidsverschil met JCHR en zeker SWI-Prolog.

\subsection{Priemgetallen} \label{sec:bench-primes}

Onze volgende test gaat over het bepalen van priemgetallen. Hierbij wordt het principe van de zeef van Erathostenes gebruikt: beginnen met een lijst van alle natuurlijke getallen van 2 tot en met tot waar de priemgetallen gevraagd zijn, om vervolgens alle getallen die deelbaar zijn door een ander getal uit de lijst te schrappen. Het algoritme is uiterst eenvoudig in (C)CHR te schrijven.
\begin{exCode}
\begin{Verbatim}[frame=single,numbers=left]
cchr {
    constraint candidate(int),prime(int);

    gen @ candidate(N) <=> N>1 | candidate(N-1), prime(N);
    sift @ prime(Y) \ prime(X) <=> (X%Y)==0 | true;
}
\end{Verbatim}
\caption{\label{code:primes} Priemgetallen in CCHR}
\end{exCode}
\benchfig{primes}{Primes benchmark}
De resultaten zijn te vinden in figuur~\ref{fig:bench-primes}. De ``problem size'' komt overeen met het getal tot waar alle priemgetallen gevraagd zijn. Voor de C versie van het algoritme wordt een array bijgehouden van alle reeds gevonden priemgetallen, en geprobeerd daar \'e\'en voor \'e\'en opeenvolgende getallen aan toe te voegen, door te controleren of er geen deelbaarheid is met een van de eerder gevonden getallen. Het toenemende tijdsverschil tussen de CCHR en C versie, is te verklaren door de kleine toename in rekentijd die optreedt bij groter wordende constraint store en indexen, waar de C versie geen last van heeft.

Er bestaan trouwens veel betere algoritmes om dit te implementeren, die in C nauwelijks moeilijker te implementeren zijn. Bijvoorbeeld slechts proberen te delen door priemgetallen tot en met $\sqrt{N}$ zorgt reeds voor hogere snelheid. Om de test eerlijk te houden in vergelijking met CHR, is deze optimalisatie niet doorgevoerd.

\subsection{Takeuchi functie} \label{sec:bench-tak}

Als vierde test in de rij wordt een programma beschouwd om de Takeuchi functie te berekenen. Dit is een functie $tak(X,Y,Z)$ van 3 natuurlijke getallen $X$, $Y$ en $Z$, die gedefinieerd is als:
\begin{equation*}
tak(X,Y,Z) = 
\begin{cases} 
  Z & \text{als $X <= Y$,} \\
  tak(tak(X-1,Y,Z),tak(Y-1,Z,X),tak(Z-1,X,Y)) & \text{als $X > Y$.}
\end{cases}
\end{equation*}
Het is duidelijk dat deze functie extreem recursief van aard is, en zonder maatregelen zou de grote hoop van de functie-evaluaties vele malen opnieuw uitgevoerd worden voor dezelfde argumenten. Om dit tegen te gaan wordt gebruik gemaakt van een techniek die {\em tabling} heet. Het komt er op neer dat elke berekende (of nog niet berekende) functie-evaluatie bijgehouden wordt, en indien er een tweede evaluatie met dezelfde argumenten gevraagd wordt, het antwoord hiervan onmiddellijk gelijk gesteld wordt aan het resultaat van de reeds gevraagde evaluatie. Hier wordt enkel de code voor het probleem in Prolog CHR gegeven, die overzichtelijker is. De CCHR code is te vinden in de appendix.
\begin{exCode}
\begin{Verbatim}[frame=single,numbers=left]
:- chr_constraint tak(+int,+int,+int, ?int).

tak(X,Y,Z,A1) \ tak(X,Y,Z,A2) <=> A1=A2.
tak(X,Y,Z,A) ==> X =< Y | Z = A.
tak(X,Y,Z,A) ==> X > Y | 
        X1 is X-1, Y1 is Y-1, Z1 is Z-1,
        tak(X1,Y,Z,A1), tak(Y1,Z,X,A2), tak(Z1,X,Y,A3),
        tak(A1,A2,A3,A).
\end{Verbatim}
\caption{\label{code:tak} De Takeuchi functie in Prolog CHR}
\end{exCode}
Er was wat moeite nodig om een versie in C te schrijven van dit algoritme, dat sneller was dan CCHR. Uiteindelijk bleek de reeds berekende waarden in een hashtable bewaren (zie sectie~\ref{ssec:impl-rt-ht}) voldoende. Bij een eerdere poging om alle eerder berekende waardes in een 3-dimensionele array te bewaren, bleken de hoge geheugenvereisten voor vertraging te zorgen.

\benchfig{tak}{Takeuchi benchmark}
De resultaten zijn te vinden in figuur~\ref{fig:bench-tak}. Bij probleemgrootte $N$, is de waarde van $tak(\lceil\frac{100}{81}N\rceil,\lceil\frac{10}{9}N\rceil,N)$ berekend.

\subsection{Kleiner-dan-of-gelijk-aan} \label{sec:bench-leq}

Het voorlaatste voorbeeld dat bewordt, is de kleiner-dan-of-gelijk-aan test. Er wordt een cyclus gebouwd van $N$ variabelen, die elk kleiner dan of gelijk aan de vorige zijn, inclusief de eerste kleiner of gelijk aan de laatste. Dit wordt als invoer gegeven aan een programma dat dan mbv. de definitie van de orde-operator moet besluiten dat alle variabelen aan elkaar gelijk zijn. Hier wordt alweer enkel de code voor Prolog CHR, de versie voor CCHR vindt u in sectie~\ref{sec:leq-cchr}.
\begin{exCode}
\begin{Verbatim}[frame=single,numbers=left]
:- chr_constraint leq/2.

reflexivity  @ leq(X,X) <=> true.
antisymmetry @ leq(X,Y), leq(Y,X) <=> X = Y.
idempotence  @ leq(X,Y) \ leq(X,Y) <=> true.
transitivity @ leq(X,Y), leq(Y,Z) ==> leq(X,Z).
\end{Verbatim}
\caption{\label{code:tak} LEQ in Prolog CHR}
\end{exCode}
Na enkele pogingen een snelle C versie van dit algoritme te schrijven, is besloten de CCHR compiler output letterlijk naar C te vertalen, maar met gebruik van geschiktere datastructuren. In het bijzonder is hier in plaats van een constraint store slechts een matrix van $N$ op $N$ (met $N$ het aantal variabelen) gebruikt, waarvan elke cel aangeeft hoe vaak een constraint die een $\leq$ uitdrukt geactiveerd werd. Voor de gelijkheden te volgen worden dezelfde logische variabelen gebruikt als in CCHR. De code is eveneens te vinden in sectie~\ref{code:leq-c}.
\benchfig{leq}{LEQ benchmark}
De resultaten zijn te vinden in figuur~\ref{fig:bench-leq}. Opvallend is de helling die bij CCHR hoger is dan bij C, veroorzaakt door de vele overbodige reactivaties. De JCHR en Prolog versie zijn wel trager, maar het is niet duidelijk of ze dezelfde sterkere helling vertonen.

\subsection{Ram simulator} \label{sec:bench-ram}

Het laatste testvoorbeeld dat beschouwd wordt is de RAM simulator in CHR, zoals beschreven in \cite{jon:complexity:chr05}.
Hierin wordt een simpel programmaatje dat van $N$ tot $0$ telt geladen, met $N$ de ``problem size''. De code is bijna identiek aan de Prolog versie, en is te vinden in sectie~\ref{sec:ram-cchr}. \benchfig{ram}{RAM benchmark}. De resultaten zijn te vinden in figuur~\ref{fig:bench-ram}. Het opvallendste is het bijna perfect lineair zijn van het voorbeeld in alle talen, met enkel constante factoren ertussen. In de C versie is het hele programma een enkele lus die een instructie leest, en binnen een {\em switch} uitvoert. Hierbij is helemaal geen tijd die verloren gaat aan het opzoeken van elementen in het geheugen.

\section{Correctheid} \label{sec:correctheid}

\subsection{Standaarden} \label{sec:standards}

Alle code, zowel de compiler als de gegenereerde code, is C code, of iets dat ernaar omgezet wordt. De programmeertaal C bestaat echter in vele varianten en er zijne vele standaarden voor gedefinieerd. Wat betreft de C compiler is steeds gebruik gemaakt van de {\em GNU Compiler Collection} (GCC). De compiler heeft geen externe afhankelijkheden van andere projecten of bibliotheken, en is volledig conform aan de ``C99'' standaard (ISO 9899:1999). Merk op dat GCC zelf nog niet volledig C99 ondersteunt, maar de broncode gebruikt ook geen functionaliteit die niet in GCC 3.3 aanwezig is. De gegenereerde code, of beter gezegd, de huidige CSM definities, maken gebruik van 1 mogelijkheid die niet tot de C99 standaard behoort, en slechts vanaf GCC 4 beschikbaar is: ``local labels''. Deze worden gebruikt om uit geneste lussen te springen op een elegante manier.

\subsection{Geheugenlekken} \label{sec:memleaks}

\Quote{It's no use carrying an umbrella if your shoes are leaking.}{Irish proverb}

In beide gevallen wordt vaak gebruik gemaakt van het dynamisch geheugen dat deze taal aanbiedt, mbv. de systeemfuncties \code{malloc()}, \code{free()} en \code{realloc()}. Het probleem met gebruik hiervan is dat de programmeur volledig zelf verantwoordelijk wordt voor het geheugenbeheer. Er moet voor gezorgd worden dat elke byte gealloceerd geheugen ook effectief vrijgegeven wordt, en dat er nooit naar niet-gealloceerd of reeds-vrijgegeven geheugen verwezen wordt. Om deze fouten te kunnen opsporen is gebruik gemaakt van de geheugen debuggers {\em valgrind} en {\em Electric Fence}, en met de  {\em boundschecking} patch voor GCC. Zowel de compiler zelf als de gegenereerde code zijn vaak met deze tools gecontroleerd, en in de uiteindelijke versie zijn dan ook geen ``geheugenlekken'' of gebruik van niet-gealloceerd geheugen meer gevonden.

Uiteraard blijft de gebruiker van de CCHR compiler wel verantwoordelijk om zelf geen geheugenlekken te veroorzaken, bv. door C code die in de body van een CHR rule staat.
